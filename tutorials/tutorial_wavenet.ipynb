{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('../names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... --> y\n",
      "..y --> u\n",
      ".yu --> h\n",
      "yuh --> e\n",
      "uhe --> n\n",
      "hen --> g\n",
      "eng --> .\n",
      "... --> d\n",
      "..d --> i\n",
      ".di --> o\n",
      "dio --> n\n",
      "ion --> d\n",
      "ond --> r\n",
      "ndr --> e\n",
      "dre --> .\n",
      "... --> x\n",
      "..x --> a\n",
      ".xa --> v\n",
      "xav --> i\n",
      "avi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / (fan_in ** 0.5)\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # params trained with backprop\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers trained with momentum update\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=0, keepdim=True)\n",
    "            xvar = x.var(dim=0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum) * self.running_var + self.momentum*xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "C  = torch.randn((vocab_size, n_embd))\n",
    "layers = [\n",
    "    Linear(n_embd * block_size, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make it less confident\n",
    "    layers[-1].weight *= 0.1\n",
    "    # all other layers: apply gain\n",
    "\n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3009\n",
      "  10000/ 200000: 2.2558\n",
      "  20000/ 200000: 2.0448\n",
      "  30000/ 200000: 1.9628\n",
      "  40000/ 200000: 2.6019\n",
      "  50000/ 200000: 2.3491\n",
      "  60000/ 200000: 2.4057\n",
      "  70000/ 200000: 1.9998\n",
      "  80000/ 200000: 1.7739\n",
      "  90000/ 200000: 2.1271\n",
      " 100000/ 200000: 1.9799\n",
      " 110000/ 200000: 2.0661\n",
      " 120000/ 200000: 2.2353\n",
      " 130000/ 200000: 2.2805\n",
      " 140000/ 200000: 2.0675\n",
      " 150000/ 200000: 2.1004\n",
      " 160000/ 200000: 1.8342\n",
      " 170000/ 200000: 2.1820\n",
      " 180000/ 200000: 2.2115\n",
      " 190000/ 200000: 1.9646\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  emb = C[Xb] # embed the characters into vectors\n",
    "  x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "  for layer in layers:\n",
    "    x = layer(x)\n",
    "  loss = F.cross_entropy(x, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x149e07850>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing the loss plot to not appear so jancky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x149c347c0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding embedding look up table and flattening to the our class and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / (fan_in ** 0.5)\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # params trained with backprop\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers trained with momentum update\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=0, keepdim=True)\n",
    "            xvar = x.var(dim=0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum) * self.running_var + self.momentum*xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))    \n",
    "\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class Flatten:\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Sequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    Flatten(),\n",
    "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make it less confident ????\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3259\n",
      "  10000/ 200000: 2.1709\n",
      "  20000/ 200000: 2.2307\n",
      "  30000/ 200000: 2.8273\n",
      "  40000/ 200000: 2.2703\n",
      "  50000/ 200000: 2.3442\n",
      "  60000/ 200000: 2.3022\n",
      "  70000/ 200000: 2.4125\n",
      "  80000/ 200000: 2.0850\n",
      "  90000/ 200000: 1.8623\n",
      " 100000/ 200000: 2.2876\n",
      " 110000/ 200000: 2.3693\n",
      " 120000/ 200000: 2.2139\n",
      " 130000/ 200000: 2.1719\n",
      " 140000/ 200000: 2.4925\n",
      " 150000/ 200000: 2.3460\n",
      " 160000/ 200000: 2.5159\n",
      " 170000/ 200000: 2.1958\n",
      " 180000/ 200000: 2.3488\n",
      " 190000/ 200000: 2.0782\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0624382495880127\n",
      "val 2.106109619140625\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graylynn.\n",
      "keani.\n",
      "amarel.\n",
      "jahsibrie.\n",
      "dasean.\n",
      "miqeoniam.\n",
      "samardanxant.\n",
      "kael.\n",
      "nylan.\n",
      "campeye.\n",
      "casa.\n",
      "khalajeazisbette.\n",
      "akannah.\n",
      "markel.\n",
      "eblyi.\n",
      "angel.\n",
      "keigh.\n",
      "aile.\n",
      "jaliy.\n",
      "jaycie.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass the neural net\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building WaveNet: A Generative Model for Raw Audio by DeepMind Oord et al (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 8]) torch.Size([182625])\n",
      "torch.Size([22655, 8]) torch.Size([22655])\n",
      "torch.Size([22866, 8]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ --> y\n",
      ".......y --> u\n",
      "......yu --> h\n",
      ".....yuh --> e\n",
      "....yuhe --> n\n",
      "...yuhen --> g\n",
      "..yuheng --> .\n",
      "........ --> d\n",
      ".......d --> i\n",
      "......di --> o\n",
      ".....dio --> n\n",
      "....dion --> d\n",
      "...diond --> r\n",
      "..diondr --> e\n",
      ".diondre --> .\n",
      "........ --> x\n",
      ".......x --> a\n",
      "......xa --> v\n",
      ".....xav --> i\n",
      "....xavi --> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22097\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    Flatten(),\n",
    "    Linear(n_embd * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make it less confident ????\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0, 11,  1, 13,  5, 12],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 19,  8,  5, 12, 12, 25],\n",
       "        [ 5, 22,  9,  1, 20,  8,  1, 14]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,)) # batch size of 4 examples\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].out.shape # Embeddings layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 80])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].out.shape # Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].out.shape # Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 200])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(4,80) @ torch.randn(80,200) + torch.randn(200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 200])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplcation is a powerful operation in python. We have a higher dimension tensors and still it works\n",
    "(torch.randn(4,5,80) @ torch.randn(80,200) + torch.randn(200)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 200])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use this idea during our model we have to group two chars \n",
    "# (1 2) (3 4) (5 6) (7 8)\n",
    "(torch.randn(4, 4, 20) @ torch.randn(20,200) + torch.randn(200)).shape # we only want two chars to come in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2972\n",
      "  10000/ 200000: 2.4881\n",
      "  20000/ 200000: 2.0795\n",
      "  30000/ 200000: 2.1836\n",
      "  40000/ 200000: 1.7859\n",
      "  50000/ 200000: 2.1584\n",
      "  60000/ 200000: 2.1223\n",
      "  70000/ 200000: 1.7846\n",
      "  80000/ 200000: 1.7030\n",
      "  90000/ 200000: 1.4805\n",
      " 100000/ 200000: 1.8621\n",
      " 110000/ 200000: 2.0719\n",
      " 120000/ 200000: 2.0434\n",
      " 130000/ 200000: 1.9284\n",
      " 140000/ 200000: 2.3975\n",
      " 150000/ 200000: 1.8070\n",
      " 160000/ 200000: 1.7874\n",
      " 170000/ 200000: 2.1998\n",
      " 180000/ 200000: 2.1817\n",
      " 190000/ 200000: 2.2299\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.9169845581054688\n",
      "val 2.0180788040161133\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding changes to make batches of 2 to process for WaveNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.randn(4,8,10) # goal: want this to (4, 4, 20) where consecutive 10-d vectors get concatanated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 20])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicit = torch.cat([e[:, ::2, :], e[:, 1::2, :]], dim=2)\n",
    "explicit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e.view(4,4,20) == explicit).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / (fan_in ** 0.5)\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # params trained with backprop\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers trained with momentum update\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=0, keepdim=True)\n",
    "            xvar = x.var(dim=0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum) * self.running_var + self.momentum*xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "\n",
    "class Tanh:\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))    \n",
    "\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class FlattenConsecutive:\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1: # spurious dimension, can be squeezed out\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Sequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 68 \n",
    "n_consecutive = 2\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_embd, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, 11,  9, 16, 20, 25, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  0,  0,  7, 18,  1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,)) # batch size of 4 examples\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 10)\n",
      "FlattenConsecutive : (4, 4, 20)\n",
      "Linear : (4, 4, 68)\n",
      "BatchNorm1d : (4, 4, 68)\n",
      "Tanh : (4, 4, 68)\n",
      "FlattenConsecutive : (4, 2, 136)\n",
      "Linear : (4, 2, 68)\n",
      "BatchNorm1d : (4, 2, 68)\n",
      "Tanh : (4, 2, 68)\n",
      "FlattenConsecutive : (4, 136)\n",
      "Linear : (4, 68)\n",
      "BatchNorm1d : (4, 68)\n",
      "Tanh : (4, 68)\n",
      "Linear : (4, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3052\n",
      "  10000/ 200000: 1.8562\n",
      "  20000/ 200000: 1.9144\n",
      "  30000/ 200000: 2.2990\n",
      "  40000/ 200000: 2.0675\n",
      "  50000/ 200000: 2.1388\n",
      "  60000/ 200000: 1.9065\n",
      "  70000/ 200000: 1.9931\n",
      "  80000/ 200000: 2.0172\n",
      "  90000/ 200000: 2.1176\n",
      " 100000/ 200000: 1.8640\n",
      " 110000/ 200000: 1.9316\n",
      " 120000/ 200000: 1.6935\n",
      " 130000/ 200000: 1.8792\n",
      " 140000/ 200000: 2.1087\n",
      " 150000/ 200000: 1.5997\n",
      " 160000/ 200000: 1.6496\n",
      " 170000/ 200000: 1.9802\n",
      " 180000/ 200000: 2.0844\n",
      " 190000/ 200000: 1.5890\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.940755844116211\n",
      "val 2.031040906906128\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't a performance increase from what we had earlier. One reason could be how batchnorm is working. It was modeled to work for 2d data but now we are passing a three dim tensor and we need to change the implementation to account for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing BatchNorm1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (32, 8, 10)\n",
      "FlattenConsecutive : (32, 4, 20)\n",
      "Linear : (32, 4, 68)\n",
      "BatchNorm1d : (32, 4, 68)\n",
      "Tanh : (32, 4, 68)\n",
      "FlattenConsecutive : (32, 2, 136)\n",
      "Linear : (32, 2, 68)\n",
      "BatchNorm1d : (32, 2, 68)\n",
      "Tanh : (32, 2, 68)\n",
      "FlattenConsecutive : (32, 136)\n",
      "Linear : (32, 68)\n",
      "BatchNorm1d : (32, 68)\n",
      "Tanh : (32, 68)\n",
      "Linear : (32, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emean shape: torch.Size([1, 4, 68])\n",
      "evar shape: torch.Size([1, 4, 68])\n",
      "ehat shape: torch.Size([32, 4, 68])\n"
     ]
    }
   ],
   "source": [
    "e = torch.randn(32, 4, 68)\n",
    "emean = e.mean(0, keepdim=True)\n",
    "print(f'emean shape: {emean.shape}') # 1, 4, 68\n",
    "evar = e.var(0, keepdim=True)\n",
    "print(f'evar shape: {evar.shape}') # 1, 4, 68\n",
    "ehat = (e - emean) / torch.sqrt(evar + 1e-5)\n",
    "print(f'ehat shape: {ehat.shape}') # 32, 4, 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 68])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emean shape: torch.Size([1, 1, 68])\n",
      "evar shape: torch.Size([1, 1, 68])\n",
      "ehat shape: torch.Size([32, 4, 68])\n"
     ]
    }
   ],
   "source": [
    "e = torch.randn(32, 4, 68)\n",
    "emean = e.mean((0,1), keepdim=True)\n",
    "print(f'emean shape: {emean.shape}') # 1, 1, 68\n",
    "evar = e.var((0,1), keepdim=True)\n",
    "print(f'evar shape: {evar.shape}') # 1, 1, 68\n",
    "ehat = (e - emean) / torch.sqrt(evar + 1e-5)\n",
    "print(f'ehat shape: {ehat.shape}') # 32, 4, 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 68])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out)) / (fan_in ** 0.5)\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "    \n",
    "class BatchNorm1d:\n",
    "\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # params trained with backprop\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers trained with momentum update\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate forward pass\n",
    "        if self.training:\n",
    "            if x.ndim == 2:\n",
    "                xmean = x.mean(dim=0, keepdim=True)\n",
    "                xvar = x.var(dim=0, keepdim=True)\n",
    "            elif x.ndim == 3:\n",
    "                xmean = x.mean(dim=(0,1), keepdim=True)\n",
    "                xvar = x.var(dim=(0,1), keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum*xmean\n",
    "                self.running_var = (1-self.momentum) * self.running_var + self.momentum*xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "\n",
    "class Tanh:\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "\n",
    "class Embedding:\n",
    "\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        self.weight = torch.randn((num_embeddings, embedding_dim))    \n",
    "\n",
    "    def __call__(self, IX):\n",
    "        self.out = self.weight[IX]\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.weight]\n",
    "\n",
    "class FlattenConsecutive:\n",
    "\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        B, T, C = x.shape\n",
    "        x = x.view(B, T//self.n, C*self.n)\n",
    "        if x.shape[1] == 1: # spurious dimension, can be squeezed out\n",
    "            x = x.squeeze(1)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Sequential:\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        self.out = x\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22397\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 68 \n",
    "n_consecutive = 2\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_embd, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2523\n",
      "  10000/ 200000: 2.5889\n",
      "  20000/ 200000: 2.1162\n",
      "  30000/ 200000: 2.2239\n",
      "  40000/ 200000: 1.8654\n",
      "  50000/ 200000: 2.2695\n",
      "  60000/ 200000: 2.2023\n",
      "  70000/ 200000: 1.9162\n",
      "  80000/ 200000: 2.1144\n",
      "  90000/ 200000: 1.7057\n",
      " 100000/ 200000: 2.6469\n",
      " 110000/ 200000: 2.0350\n",
      " 120000/ 200000: 2.1125\n",
      " 130000/ 200000: 2.1534\n",
      " 140000/ 200000: 1.8334\n",
      " 150000/ 200000: 1.9982\n",
      " 160000/ 200000: 2.1880\n",
      " 170000/ 200000: 2.1074\n",
      " 180000/ 200000: 2.3232\n",
      " 190000/ 200000: 2.2386\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (32, 8, 10)\n",
      "FlattenConsecutive : (32, 4, 20)\n",
      "Linear : (32, 4, 68)\n",
      "BatchNorm1d : (32, 4, 68)\n",
      "Tanh : (32, 4, 68)\n",
      "FlattenConsecutive : (32, 2, 136)\n",
      "Linear : (32, 2, 68)\n",
      "BatchNorm1d : (32, 2, 68)\n",
      "Tanh : (32, 2, 68)\n",
      "FlattenConsecutive : (32, 136)\n",
      "Linear : (32, 68)\n",
      "BatchNorm1d : (32, 68)\n",
      "Tanh : (32, 68)\n",
      "Linear : (32, 27)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 68])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.9112660884857178\n",
      "val 2.02042818069458\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding it all together and increasing embedding dimension and hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76579\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24\n",
    "n_hidden = 128 \n",
    "n_consecutive = 2\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_embd, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(n_consecutive), Linear(n_consecutive*n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size)\n",
    "])\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.layers[-1].weight *= 0.1\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3098\n",
      "  10000/ 200000: 2.1817\n",
      "  20000/ 200000: 1.9887\n",
      "  30000/ 200000: 1.9058\n",
      "  40000/ 200000: 1.7113\n",
      "  50000/ 200000: 1.8282\n",
      "  60000/ 200000: 2.0987\n",
      "  70000/ 200000: 1.9342\n",
      "  80000/ 200000: 1.7627\n",
      "  90000/ 200000: 2.0211\n",
      " 100000/ 200000: 1.6985\n",
      " 110000/ 200000: 1.7918\n",
      " 120000/ 200000: 2.1039\n",
      " 130000/ 200000: 1.8139\n",
      " 140000/ 200000: 1.7254\n",
      " 150000/ 200000: 1.7145\n",
      " 160000/ 200000: 1.7206\n",
      " 170000/ 200000: 2.0210\n",
      " 180000/ 200000: 2.0005\n",
      " 190000/ 200000: 1.6668\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  # forward pass\n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 10000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x167544910>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.7682349681854248\n",
      "val 1.989533543586731\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performance logs:\n",
    "1. original (3 character context + 200 neurons + 12k params) train 2.0624382495880127 val 2.106109619140625\n",
    "2. next context 8 characters + 20k params train 1.9169845581054688 val 2.0180788040161133\n",
    "3. flat --> heirarchical model 22k params train 1.940755844116211 val 2.031040906906128\n",
    "4. bugfix in batchnorm1d train 1.9112660884857178 val 2.02042818069458\n",
    "5. scaling up the model n_emd = 24 and n_hidden = 128 76k params train 1.7682349681854248 val 1.989533543586731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
